{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e9e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pishva_r\\AppData\\Local\\Temp\\ipykernel_8576\\231190679.py:9: DtypeWarning: Columns (8,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(file_df1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ خروجی در فایل merged_output.csv ذخیره شد\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # ---- تنظیم نام فایل‌ها ----\n",
    "# file_df1 = \"power_code_clean.csv\"\n",
    "# file_df2 = \"12209_G13.csv\"\n",
    "# file_df3 = \"12210_G13.csv\"\n",
    "\n",
    "# # ---- مرحله 1: خواندن فایل اول و فیلتر کردن UNIT_NO=3 ----\n",
    "# df1 = pd.read_csv(file_df1)\n",
    "# df1 = df1[df1[\"UNIT_NO\"] == 3].copy()\n",
    "\n",
    "# # تبدیل TIMESTAMPS به datetime\n",
    "# df1[\"TIMESTAMPS\"] = pd.to_datetime(df1[\"TIMESTAMPS\"], errors=\"coerce\")\n",
    "# df1 = df1.dropna(subset=[\"TIMESTAMPS\"])\n",
    "\n",
    "# # ---- مرحله 2: خواندن دو فایل دوم و سوم ----\n",
    "# df2 = pd.read_csv(file_df2)\n",
    "# df3 = pd.read_csv(file_df3)\n",
    "\n",
    "# df2[\"TimeStamp\"] = pd.to_datetime(df2[\"TimeStamp\"], errors=\"coerce\")\n",
    "# df3[\"TimeStamp\"] = pd.to_datetime(df3[\"TimeStamp\"], errors=\"coerce\")\n",
    "\n",
    "# df2 = df2.dropna(subset=[\"TimeStamp\", \"Value\"])\n",
    "# df3 = df3.dropna(subset=[\"TimeStamp\", \"Value\"])\n",
    "\n",
    "# # ---- مرحله 3 و 4: افزودن ستون‌ها با نام فایل‌های دوم و سوم به df1 ----\n",
    "# df1[file_df2] = pd.NA\n",
    "# df1[file_df3] = pd.NA\n",
    "\n",
    "# # ---- مرتب‌سازی برای merge_asof ----\n",
    "# df1_sorted = df1.sort_values(\"TIMESTAMPS\").copy()\n",
    "# df1_sorted[\"__orig_index__\"] = df1_sorted.index\n",
    "\n",
    "# df2_sorted = df2.sort_values(\"TimeStamp\")[[\"TimeStamp\", \"Value\"]].copy()\n",
    "# df3_sorted = df3.sort_values(\"TimeStamp\")[[\"TimeStamp\", \"Value\"]].copy()\n",
    "\n",
    "# # ---- مرحله 5: نزدیک‌ترین تایم‌استمپ از df2 ----\n",
    "# m2 = pd.merge_asof(\n",
    "#     df1_sorted[[\"__orig_index__\", \"TIMESTAMPS\"]],\n",
    "#     df2_sorted,\n",
    "#     left_on=\"TIMESTAMPS\",\n",
    "#     right_on=\"TimeStamp\",\n",
    "#     direction=\"nearest\"\n",
    "# )\n",
    "# df1.loc[m2[\"__orig_index__\"], file_df2] = m2[\"Value\"].values\n",
    "\n",
    "# # ---- مرحله 6: نزدیک‌ترین تایم‌استمپ از df3 ----\n",
    "# m3 = pd.merge_asof(\n",
    "#     df1_sorted[[\"__orig_index__\", \"TIMESTAMPS\"]],\n",
    "#     df3_sorted,\n",
    "#     left_on=\"TIMESTAMPS\",\n",
    "#     right_on=\"TimeStamp\",\n",
    "#     direction=\"nearest\"\n",
    "# )\n",
    "# df1.loc[m3[\"__orig_index__\"], file_df3] = m3[\"Value\"].values\n",
    "\n",
    "# # ---- بازگردانی ترتیب اولیه ----\n",
    "# df1 = df1.sort_index()\n",
    "\n",
    "# # ---- ذخیره خروجی در فایل CSV جدید ----\n",
    "# df1.to_csv(\"merged_output.csv\", index=False)\n",
    "\n",
    "# print(\"✅ خروجی در فایل merged_output.csv ذخیره شد\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c13bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pishva_r\\AppData\\Local\\Temp\\ipykernel_8576\\3402275214.py:15: DtypeWarning: Columns (8,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(file_df1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ خروجی در فایل merged_output.csv ذخیره شد\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # ---- تنظیم نام فایل‌ها ----\n",
    "# file_df1 = \"power_code_clean.csv\"\n",
    "# file_df2 = \"12209_G13.csv\"\n",
    "# file_df3 = \"12210_G13.csv\"\n",
    "# file_ebraz = \"ebraz.csv\"\n",
    "\n",
    "# # ---- استخراج نام پایه بدون پسوند .csv ----\n",
    "# base_df2 = file_df2.replace(\".csv\", \"\")\n",
    "# base_df3 = file_df3.replace(\".csv\", \"\")\n",
    "# base_ebraz = file_ebraz.replace(\".csv\", \"\")\n",
    "\n",
    "# # ---- مرحله 1: خواندن فایل اول و فیلتر کردن UNIT_NO=3 ----\n",
    "# df1 = pd.read_csv(file_df1)\n",
    "# df1 = df1[df1[\"UNIT_NO\"] == 3].copy()\n",
    "\n",
    "# # تبدیل TIMESTAMPS به datetime\n",
    "# df1[\"TIMESTAMPS\"] = pd.to_datetime(df1[\"TIMESTAMPS\"], errors=\"coerce\")\n",
    "# df1 = df1.dropna(subset=[\"TIMESTAMPS\"])\n",
    "\n",
    "# # ---- مرحله 2: خواندن دو فایل دوم و سوم ----\n",
    "# df2 = pd.read_csv(file_df2)\n",
    "# df3 = pd.read_csv(file_df3)\n",
    "\n",
    "# df2[\"TimeStamp\"] = pd.to_datetime(df2[\"TimeStamp\"], errors=\"coerce\")\n",
    "# df3[\"TimeStamp\"] = pd.to_datetime(df3[\"TimeStamp\"], errors=\"coerce\")\n",
    "\n",
    "# df2 = df2.dropna(subset=[\"TimeStamp\", \"Value\"])\n",
    "# df3 = df3.dropna(subset=[\"TimeStamp\", \"Value\"])\n",
    "\n",
    "# # ---- مرحله 3 و 4: افزودن ستون‌ها با نام پایه به df1 ----\n",
    "# df1[base_df2] = pd.NA\n",
    "# df1[base_df3] = pd.NA\n",
    "\n",
    "# # ---- مرتب‌سازی برای merge_asof ----\n",
    "# df1_sorted = df1.sort_values(\"TIMESTAMPS\").copy()\n",
    "# df1_sorted[\"__orig_index__\"] = df1_sorted.index\n",
    "\n",
    "# df2_sorted = df2.sort_values(\"TimeStamp\")[[\"TimeStamp\", \"Value\"]].copy()\n",
    "# df3_sorted = df3.sort_values(\"TimeStamp\")[[\"TimeStamp\", \"Value\"]].copy()\n",
    "\n",
    "# # ---- مرحله 5: نزدیک‌ترین تایم‌استمپ از df2 ----\n",
    "# m2 = pd.merge_asof(\n",
    "#     df1_sorted[[\"__orig_index__\", \"TIMESTAMPS\"]],\n",
    "#     df2_sorted,\n",
    "#     left_on=\"TIMESTAMPS\",\n",
    "#     right_on=\"TimeStamp\",\n",
    "#     direction=\"nearest\"\n",
    "# )\n",
    "# df1.loc[m2[\"__orig_index__\"], base_df2] = m2[\"Value\"].values\n",
    "\n",
    "# # ---- مرحله 6: نزدیک‌ترین تایم‌استمپ از df3 ----\n",
    "# m3 = pd.merge_asof(\n",
    "#     df1_sorted[[\"__orig_index__\", \"TIMESTAMPS\"]],\n",
    "#     df3_sorted,\n",
    "#     left_on=\"TIMESTAMPS\",\n",
    "#     right_on=\"TimeStamp\",\n",
    "#     direction=\"nearest\"\n",
    "# )\n",
    "# df1.loc[m3[\"__orig_index__\"], base_df3] = m3[\"Value\"].values\n",
    "\n",
    "# # ---- بازگردانی ترتیب اولیه ----\n",
    "# df1 = df1.sort_index()\n",
    "\n",
    "# # ---- مرحله جدید: خواندن فایل ebraz و افزودن ستون POWER ----\n",
    "# df_ebraz = pd.read_csv(file_ebraz)\n",
    "\n",
    "# # افزودن ستون ebraz به df1 (خروجی نهایی)\n",
    "# df1[base_ebraz] = pd.NA\n",
    "\n",
    "# # بررسی وجود ستون‌های لازم و انجام مپینگ درست\n",
    "# # حالا ID_NO در فایل ebraz.csv با ID_EBRAZ در df1 (merged_output) مقایسه می‌شود\n",
    "# if all(col in df_ebraz.columns for col in ['ID_NO', 'POWER']) and 'ID_EBRAZ' in df1.columns:\n",
    "#     # ایجاد دیکشنری mapping: ID_NO (از ebraz) → POWER\n",
    "#     mapping = dict(zip(df_ebraz['ID_NO'], df_ebraz['POWER']))\n",
    "#     # مپ کردن ID_EBRAZ در df1 به مقدار POWER متناظر\n",
    "#     df1[base_ebraz] = df1['ID_EBRAZ'].map(mapping)\n",
    "# elif all(col in df_ebraz.columns for col in ['ID_EBRAZ', 'POWER']) and 'ID_NO' in df1.columns:\n",
    "#     # fallback قبلی (در صورت اشتباه در نام ستون)\n",
    "#     mapping = dict(zip(df_ebraz['ID_EBRAZ'], df_ebraz['POWER']))\n",
    "#     df1[base_ebraz] = df1['ID_NO'].map(mapping)\n",
    "# else:\n",
    "#     print(\"⚠️ ستون‌های لازم برای مپینگ ebraz یافت نشد. لطفاً نام ستون‌ها را بررسی کنید.\")\n",
    "\n",
    "# # ---- ذخیره خروجی در فایل CSV جدید ----\n",
    "# df1.to_csv(\"merged_output.csv\", index=False)\n",
    "\n",
    "# print(\"✅ خروجی در فایل merged_output.csv ذخیره شد\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b57878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pishva_r\\AppData\\Local\\Temp\\ipykernel_8576\\1807391543.py:15: DtypeWarning: Columns (8,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(file_df1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ خروجی بدون ستون‌های مشخص‌شده در فایل merged_output.csv ذخیره شد\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---- تنظیم نام فایل‌ها ----\n",
    "file_df1 = \"power_code_clean.csv\"\n",
    "file_df2 = \"12209_G13.csv\"\n",
    "file_df3 = \"12210_G13.csv\"\n",
    "file_ebraz = \"ebraz.csv\"\n",
    "\n",
    "# ---- استخراج نام پایه بدون پسوند .csv ----\n",
    "base_df2 = file_df2.replace(\".csv\", \"\")\n",
    "base_df3 = file_df3.replace(\".csv\", \"\")\n",
    "base_ebraz = file_ebraz.replace(\".csv\", \"\")\n",
    "\n",
    "# ---- مرحله 1: خواندن فایل اول و فیلتر کردن UNIT_NO=3 ----\n",
    "df1 = pd.read_csv(file_df1)\n",
    "df1 = df1[df1[\"UNIT_NO\"] == 3].copy()\n",
    "\n",
    "# تبدیل TIMESTAMPS به datetime\n",
    "df1[\"TIMESTAMPS\"] = pd.to_datetime(df1[\"TIMESTAMPS\"], errors=\"coerce\")\n",
    "df1 = df1.dropna(subset=[\"TIMESTAMPS\"])\n",
    "\n",
    "# ---- مرحله 2: خواندن دو فایل دوم و سوم ----\n",
    "df2 = pd.read_csv(file_df2)\n",
    "df3 = pd.read_csv(file_df3)\n",
    "\n",
    "df2[\"TimeStamp\"] = pd.to_datetime(df2[\"TimeStamp\"], errors=\"coerce\")\n",
    "df3[\"TimeStamp\"] = pd.to_datetime(df3[\"TimeStamp\"], errors=\"coerce\")\n",
    "\n",
    "df2 = df2.dropna(subset=[\"TimeStamp\", \"Value\"])\n",
    "df3 = df3.dropna(subset=[\"TimeStamp\", \"Value\"])\n",
    "\n",
    "# ---- مرحله 3 و 4: افزودن ستون‌ها با نام پایه به df1 ----\n",
    "df1[base_df2] = pd.NA\n",
    "df1[base_df3] = pd.NA\n",
    "\n",
    "# ---- مرتب‌سازی برای merge_asof ----\n",
    "df1_sorted = df1.sort_values(\"TIMESTAMPS\").copy()\n",
    "df1_sorted[\"__orig_index__\"] = df1_sorted.index\n",
    "\n",
    "df2_sorted = df2.sort_values(\"TimeStamp\")[[\"TimeStamp\", \"Value\"]].copy()\n",
    "df3_sorted = df3.sort_values(\"TimeStamp\")[[\"TimeStamp\", \"Value\"]].copy()\n",
    "\n",
    "# ---- مرحله 5: نزدیک‌ترین تایم‌استمپ از df2 ----\n",
    "m2 = pd.merge_asof(\n",
    "    df1_sorted[[\"__orig_index__\", \"TIMESTAMPS\"]],\n",
    "    df2_sorted,\n",
    "    left_on=\"TIMESTAMPS\",\n",
    "    right_on=\"TimeStamp\",\n",
    "    direction=\"nearest\"\n",
    ")\n",
    "df1.loc[m2[\"__orig_index__\"], base_df2] = m2[\"Value\"].values\n",
    "\n",
    "# ---- مرحله 6: نزدیک‌ترین تایم‌استمپ از df3 ----\n",
    "m3 = pd.merge_asof(\n",
    "    df1_sorted[[\"__orig_index__\", \"TIMESTAMPS\"]],\n",
    "    df3_sorted,\n",
    "    left_on=\"TIMESTAMPS\",\n",
    "    right_on=\"TimeStamp\",\n",
    "    direction=\"nearest\"\n",
    ")\n",
    "df1.loc[m3[\"__orig_index__\"], base_df3] = m3[\"Value\"].values\n",
    "\n",
    "# ---- بازگردانی ترتیب اولیه ----\n",
    "df1 = df1.sort_index()\n",
    "\n",
    "# ---- مرحله جدید: خواندن فایل ebraz و افزودن ستون POWER ----\n",
    "df_ebraz = pd.read_csv(file_ebraz)\n",
    "\n",
    "# افزودن ستون ebraz به df1 (خروجی نهایی)\n",
    "df1[base_ebraz] = pd.NA\n",
    "\n",
    "# مپینگ درست: ID_NO در ebraz.csv → POWER و مقایسه با ID_EBRAZ در df1\n",
    "if all(col in df_ebraz.columns for col in ['ID_NO', 'POWER']) and 'ID_EBRAZ' in df1.columns:\n",
    "    mapping = dict(zip(df_ebraz['ID_NO'], df_ebraz['POWER']))\n",
    "    df1[base_ebraz] = df1['ID_EBRAZ'].map(mapping)\n",
    "elif all(col in df_ebraz.columns for col in ['ID_EBRAZ', 'POWER']) and 'ID_NO' in df1.columns:\n",
    "    mapping = dict(zip(df_ebraz['ID_EBRAZ'], df_ebraz['POWER']))\n",
    "    df1[base_ebraz] = df1['ID_NO'].map(mapping)\n",
    "else:\n",
    "    print(\"⚠️ ستون‌های لازم برای مپینگ ebraz یافت نشد. لطفاً نام ستون‌ها را بررسی کنید.\")\n",
    "\n",
    "# ---- حذف ستون‌های خواسته‌شده ----\n",
    "columns_to_drop = [\"CODE2\", \"FLAG\", \"ID_PP\", \"CODE3\", \"CODE4\", \"MVAR\"]\n",
    "# فقط ستون‌هایی که وجود دارند را حذف می‌کنیم تا خطا ندهد\n",
    "df1 = df1.drop(columns=[col for col in columns_to_drop if col in df1.columns])\n",
    "\n",
    "# ---- ذخیره خروجی در فایل CSV جدید ----\n",
    "df1.to_csv(\"merged_output.csv\", index=False)\n",
    "\n",
    "print(\"✅ خروجی بدون ستون‌های مشخص‌شده در فایل merged_output.csv ذخیره شد\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
